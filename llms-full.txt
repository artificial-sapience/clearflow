<project title="ClearFlow">> Compose type-safe flows for emergent AI.<quick start><doc title="Install from PyPI" desc="pip install clearflow"><!DOCTYPE html>
<html lang="en">
  <head>
    <meta
      http-equiv="Content-Security-Policy"
      content="default-src 'self'; img-src 'self' data:; media-src 'self' data:; object-src 'none'; style-src 'self' 'sha256-o4vzfmmUENEg4chMjjRP9EuW9ucGnGIGVdbl8d0SHQQ='; script-src 'self' 'sha256-KXex2o39zxtnzVWK4H5rW07g2+BlwSPtn+aguzsWkNg=';"
    />
    <link
      href="/_fs-ch-1T1wmsGaOgGaSxcX/assets/inter-var.woff2"
      rel="preload"
      as="font"
      type="font/woff2"
      crossorigin
    />
    <link href="/_fs-ch-1T1wmsGaOgGaSxcX/assets/styles.css" rel="stylesheet" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Client Challenge</title>
    <style>
      #loading-error {
        font-size: 16px;
        font-family: 'Inter', sans-serif;
        margin-top: 10px;
        margin-left: 10px;
        display: none;
      }
    </style>
  </head>
  <body>
    <noscript>
      <div class="noscript-container">
        <div class="noscript-content">
          <img
            src="/_fs-ch-1T1wmsGaOgGaSxcX/assets/errorIcon.svg"
            alt=""
            role="presentation"
            class="error-icon"
          />
          <span class="noscript-span"
            >JavaScript is disabled in your browser.</span
          >
          <p>Please enable JavaScript to proceed.</p>
        </div>
      </div>
    </noscript>
    <div id="loading-error" role="alert" aria-live="polite">
      A required part of this site couldn’t load. This may be due to a browser
      extension, network issues, or browser settings. Please check your
      connection, disable any ad blockers, or try using a different browser.
    </div>
    <script>
      function loadScript(src) {
        return new Promise((resolve, reject) => {
          const script = document.createElement('script');
          script.onload = resolve;
          script.onerror = (event) => {
            console.error('Script load error event:', event);
            document.getElementById('loading-error').style.display = 'block';
            loadingError.setAttribute('aria-hidden', 'false');
            reject(
              new Error(
                `Failed to load script: ${src}, Please contact the service administrator.`
              )
            );
          };
          script.src = src;
          document.body.appendChild(script);
        });
      }

      loadScript('/_fs-ch-1T1wmsGaOgGaSxcX/errors.js')
        .then(() => {
          const script = document.createElement('script');
          script.src = '/_fs-ch-1T1wmsGaOgGaSxcX/script.js?reload=true';
          script.onerror = (event) => {
            console.error('Script load error event:', event);
            const errorMsg = new Error(
              `Failed to load script: ${script.src}. Please contact the service administrator.`
            );
            console.error(errorMsg);
            handleScriptError();
          };
          document.body.appendChild(script);
        })
        .catch((error) => {
          console.error(error);
        });
    </script>
  </body>
</html></doc></quick start><documentation><doc title="README"># ClearFlow

[![Coverage Status](https://coveralls.io/repos/github/artificial-sapience/ClearFlow/badge.svg?branch=main)](https://coveralls.io/github/artificial-sapience/ClearFlow?branch=main)
[![PyPI](https://badge.fury.io/py/clearflow.svg)](https://pypi.org/project/clearflow/)
[![PyPI Downloads](https://static.pepy.tech/personalized-badge/clearflow?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=GREEN&left_text=downloads)](https://pepy.tech/projects/clearflow)
[![type: pyright](https://img.shields.io/badge/type-pyright-blue)](https://github.com/microsoft/pyright)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
![Python](https://img.shields.io/badge/Python-3.13%2B-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

Type-safe orchestration for unpredictable AI.

## Why ClearFlow?

- **100% test coverage** – Every path proven to work
- **Type-safe transformations** – Errors caught at development time, not runtime
- **Immutable state** – No hidden mutations
- **Zero dependencies** – No hidden failure modes
- **Single exit enforcement** – No ambiguous endings

## Installation

```bash
pip install clearflow
```

> **Upgrading from v0.x?** See the [Migration Guide](MIGRATION.md) for breaking changes.

## Examples

| Name | Description |
|------|-------------|
| [Chat](examples/chat/) | Simple conversational flow with OpenAI |
| [Portfolio Analysis](examples/portfolio_analysis/) | Multi-specialist workflow for financial analysis |
| [RAG](examples/rag/) | Full retrieval-augmented generation with vector search |

## Core Concepts

### `Node[TIn, TOut]`

A unit that transforms state from `TIn` to `TOut` (or `Node[T]` when types are the same).

- `prep(state: TIn) -> TIn` – optional pre-work/validation  
- `exec(state: TIn) -> NodeResult[TOut]` – **required**; return new state + outcome  
- `post(result: NodeResult[TOut]) -> NodeResult[TOut]` – optional cleanup/logging  

Nodes are frozen dataclasses that execute async transformations without mutating input state.

### `NodeResult[T]`

Holds the **new state** and an **outcome** string used for routing.

### `flow()`

A function that creates a flow with **explicit routing**:

```python
flow("Name", start_node)
  .route(start_node, "outcome1", next_node)
  .route(next_node, "outcome2", final_node)
  .end(final_node, "done")  # exactly one termination
```

**Routing**: Routes are `(node, outcome)` pairs. Each outcome must have exactly one route.  
**Type inference**: The flow infers types from start to end, supporting transformations.  
**Composability**: A flow is itself a `Node` – compose flows within flows.

## ClearFlow vs PocketFlow

| Aspect | ClearFlow | PocketFlow |
|--------|-----------|------------|
| **State** | Immutable, passed via `NodeResult` | Mutable, passed via `shared` param |
| **Routing** | Outcome-based explicit routes | Action-based graph edges |
| **Termination** | Exactly one exit enforced | Multiple exits allowed |
| **Type safety** | Full Python 3.13+ generics | Dynamic (no annotations) |

ClearFlow emphasizes **robust, type-safe orchestration** with validation and guardrails. PocketFlow emphasizes **brevity and flexibility** with minimal overhead.

## Development

```bash
# Install uv (if not already installed)
pipx install uv

# Clone and set up development environment
git clone https://github.com/artificial-sapience/ClearFlow.git
cd ClearFlow
uv sync --all-extras     # Creates venv and installs deps automatically
./quality-check.sh       # Run all checks
```

## License

[MIT](LICENSE)

## Acknowledgments

Inspired by [PocketFlow](https://github.com/The-Pocket/PocketFlow)'s Node-Flow-State pattern.</doc><doc title="Core API" desc="Complete implementation - Node, NodeResult, Flow, and exceptions in a single module">"""ClearFlow: Zero-dependency async workflow orchestration framework.

Provides type-safe workflow composition with explicit routing and single termination.
Built for mission-critical AI orchestration.
"""

from abc import ABC, abstractmethod
from collections.abc import Mapping
from dataclasses import dataclass
from types import MappingProxyType
from typing import Protocol, cast, final, override

__all__ = [
    "Node",
    "NodeResult",
    "flow",
]

RouteKey = tuple[str, str]  # (node_name, outcome)


class NodeBase(Protocol):
    """Non-generic base protocol for all nodes.

    Provides the common interface without type parameters,
    allowing heterogeneous collections of nodes.
    """

    name: str

    async def __call__(
        self,
        state: object,  # clearflow: ignore[ARCH009]  # Type erasure needed for heterogeneous collections
    ) -> "NodeResult[object]":  # clearflow: ignore[ARCH009]  # Type erasure needed for heterogeneous collections
        """Execute the node with any state type."""
        ...


@final
@dataclass(frozen=True)
class NodeResult[T]:
    """Result of node execution.

    Attributes:
        state: The transformed state from node execution.
        outcome: The routing outcome determining next node.

    """

    state: T
    outcome: str


@dataclass(frozen=True, kw_only=True)
class Node[TIn, TOut = TIn](ABC, NodeBase):
    """Abstract base for workflow nodes.

    Subclass and implement async exec() to process state and return outcomes for routing.
    Supports optional prep() and post() hooks for setup and cleanup.

    Type parameters:
        TIn: Input state type
        TOut: Output state type (defaults to TIn for non-transforming nodes)

    """

    name: str

    def __post_init__(self) -> None:
        """Validate node configuration after initialization.

        Raises:
            ValueError: If node name is empty or contains only whitespace.

        """
        if not self.name or not self.name.strip():
            msg = f"Node name must be a non-empty string, got: {self.name!r}"
            raise ValueError(msg)

    @override
    async def __call__(self, state: TIn) -> NodeResult[TOut]:  # pyright: ignore[reportIncompatibleMethodOverride]  # NodeBase uses object for type erasure but Node preserves type safety
        """Execute node lifecycle.

        Returns:
            NodeResult containing transformed state and routing outcome.

        """
        state = await self.prep(state)
        result = await self.exec(state)
        return await self.post(result)

    async def prep(self, state: TIn) -> TIn:  # noqa: PLR6301  # Template method hook for subclasses
        """Pre-execution hook.

        Returns:
            State passed through unchanged by default.

        """
        return state

    @abstractmethod
    async def exec(self, state: TIn) -> NodeResult[TOut]:
        """Execute main node logic - must be implemented by subclasses."""
        ...

    async def post(self, result: NodeResult[TOut]) -> NodeResult[TOut]:  # noqa: PLR6301  # Template method hook for subclasses
        """Post-execution hook.

        Returns:
            Result passed through unchanged by default.

        """
        return result


@final
@dataclass(frozen=True, kw_only=True)
class _Flow[TStartIn, TEndOut = TStartIn](Node[TStartIn, TEndOut]):
    """Internal flow implementation that transforms TStartIn to TEndOut.

    Implementation note: We use 'object' for node types internally because
    Python's type system cannot track types through runtime-determined paths.
    Type safety is maintained at the public API boundaries - exec() guarantees
    TStartIn→TEndOut transformation through construction-time validation.
    """

    start: NodeBase
    routes: Mapping[RouteKey, NodeBase | None]

    @override
    async def exec(self, state: TStartIn) -> NodeResult[TEndOut]:
        """Execute the flow by routing through nodes based on outcomes.

        Returns:
            Final node result containing transformed state and None outcome.

        Raises:
            ValueError: If no route is defined for an outcome from a node.

        """
        current_node = self.start
        current_state: object = state  # clearflow: ignore[ARCH009]  # Type erasure needed for dynamic routing

        while True:
            # Execute node
            result = await current_node(current_state)
            key = (current_node.name, result.outcome)

            # Raise error if no route defined - all outcomes must be explicitly handled
            if key not in self.routes:
                msg = f"No route defined for outcome '{result.outcome}' from node '{current_node.name}'"
                raise ValueError(msg)

            # Check next node
            next_node = self.routes[key]
            if next_node is None:
                return cast("NodeResult[TEndOut]", result)

            # Continue
            current_node = next_node
            current_state = result.state


@final
@dataclass(frozen=True, kw_only=True)
class _FlowBuilder[TStartIn, TStartOut]:
    """Flow builder for composing node routes.

    Type parameters:
        TStartIn: The input type the flow accepts (from start node)
        TStartOut: The output type of the start node

    Call end() to specify where the flow ends and get the completed flow.
    """

    _name: str
    _start: Node[TStartIn, TStartOut]
    _routes: MappingProxyType[RouteKey, NodeBase | None]
    _reachable: frozenset[str]  # Node names that are reachable from start

    def _validate_and_create_route(
        self, from_node: NodeBase, outcome: str, *, is_termination: bool = False
    ) -> RouteKey:
        """Validate that a route can be added from the given node.

        Args:
            from_node: The node to route from
            outcome: The outcome that triggers this route
            is_termination: Whether this is a termination route

        Returns:
            The route key for this route

        Raises:
            ValueError: If from_node is not reachable or route already exists

        """
        # Check reachability
        if from_node.name not in self._reachable:
            action = "end at" if is_termination else "route from"
            msg = f"Cannot {action} '{from_node.name}' - not reachable from start"
            raise ValueError(msg)

        # Check for duplicate routes
        route_key: RouteKey = (from_node.name, outcome)
        if route_key in self._routes:
            msg = f"Route already defined for outcome '{outcome}' from node '{from_node.name}'"
            raise ValueError(msg)

        return route_key

    def route(
        self,
        from_node: NodeBase,
        outcome: str,
        to_node: NodeBase,
    ) -> "_FlowBuilder[TStartIn, TStartOut]":
        """Connect nodes: from_node --outcome--> to_node.

        Args:
            from_node: Source node
            outcome: Outcome that triggers this route
            to_node: Destination node (use end() for flow completion)

        Returns:
            Builder for continued route definition and flow completion

        Raises:
            ValueError: If from_node is not reachable or route already exists

        """
        route_key = self._validate_and_create_route(from_node, outcome)

        # Add route and mark to_node as reachable
        new_routes = {**self._routes, route_key: to_node}
        new_reachable = self._reachable | {to_node.name}

        return _FlowBuilder[TStartIn, TStartOut](
            _name=self._name,
            _start=self._start,
            _routes=MappingProxyType(new_routes),
            _reachable=new_reachable,
        )

    def end[TEndIn, TEndOut](
        self,
        end: Node[TEndIn, TEndOut],
        outcome: str,
    ) -> Node[TStartIn, TEndOut]:
        """End the flow at the specified node and outcome.

        This completes the flow definition by specifying where it ends.
        The flow's output type is determined by the final node's output type.

        Args:
            end: The node where the flow ends
            outcome: The outcome from this node that completes the flow

        Returns:
            A flow node that transforms TStartIn to TEndOut

        Raises:
            ValueError: If end node is not reachable or route already exists

        """
        route_key = self._validate_and_create_route(end, outcome, is_termination=True)

        new_routes = {**self._routes, route_key: None}

        return _Flow[TStartIn, TEndOut](
            name=self._name,
            start=self._start,
            routes=MappingProxyType(new_routes),
        )


def flow[TStartIn, TStartOut](
    name: str,
    start: Node[TStartIn, TStartOut],
) -> _FlowBuilder[TStartIn, TStartOut]:
    """Create a flow with the given name and starting node.

    Args:
        name: The name of the flow
        start: The starting node that accepts TStartIn and outputs TStartOut

    Returns:
        Builder for route definition and flow completion

    """
    return _FlowBuilder[TStartIn, TStartOut](
        _name=name,
        _start=start,
        _routes=MappingProxyType({}),
        _reachable=frozenset({start.name}),  # Start node is always reachable
    )</doc><doc title="CLAUDE Guidelines" desc="This file provides guidance to Claude Code (claude.ai/code) when working with code in this repositor"># CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Core Philosophy

ClearFlow provides mission-critical AI orchestration with verifiable correctness. Built for Python engineers who demand:

- **Deep immutability** - All state transformations create new immutable data structures
- **Immutable transformations** - Nodes transform state without mutation (though they may perform I/O)
- **Type safety** - Full static typing with pyright strict mode (mypy removed)
- **100% test coverage** - Every path tested, no exceptions
- **Explicit routing** - Given an outcome, the next step is always the same
- **Zero dependencies** - Stdlib only for maximum reliability

Target audience: Python engineers building mission-critical AI systems who require verifiable orchestration with explicit control flow.

## Development Commands

```bash
# Install dependencies
uv sync                    # Install runtime dependencies
uv sync --all-extras        # Install with dev dependencies

# Run quality checks (enforced before commits)
./quality-check.sh         # Runs all checks: custom linters, lint, format, type check, tests

# Custom linters (mission-critical compliance)
python3 linters/check-architecture-compliance.py  # Architecture violations
python3 linters/check-immutability.py            # Deep immutability enforcement
python3 linters/check-test-suite-compliance.py   # Test isolation and resource management

# Individual quality commands
uv run ruff check --fix clearflow tests                 # Auto-fix linting (no unsafe fixes)
uv run ruff format clearflow tests                      # Format code
uv run pyright clearflow tests                          # Type check (pyright - only type checker)
uv run pytest -x -v tests                              # Run all tests
uv run pytest -x -v tests -k "specific_test"           # Run specific test

# Coverage requirements
uv run pytest --cov=clearflow --cov-report=term-missing --cov-fail-under=100
```

## Architecture Overview

ClearFlow is a minimal orchestration framework with functional patterns and **zero third-party dependencies**. It implements a **Node-Flow-State** pattern for managing workflows that include language model calls and other async operations.

### Core Concepts

1. **Nodes**: Async functions that transform state
   - Inherit from `Node[T]` or `Node[TIn, TOut]` and override `exec()` method
   - Nodes are frozen dataclasses with a `name` field
   - Input: state of type `T` (any type: dict, TypedDict, dataclass, primitives)
   - Output: `NodeResult[T](state, outcome)`
   - Designed for explicit transformations
   - Lifecycle hooks: `prep()`, `exec()`, `post()`

2. **State**: Unconstrained - use any type T
   - Type-safe with `T` where T is any Python type
   - Natural Python operations: `{**state, "key": "value"}`
   - Encourages immutable patterns
   - Works with dict, TypedDict, dataclass, primitives

3. **Flow**: Type-safe workflow builder
   - Create with `flow("name", start_node)` function
   - Chain with `.route(from_node, outcome, to_node)`
   - End with `.end(final_node, outcome)` for single termination
   - Single termination rule: exactly one route to `None`
   - Full generic support with type inference

### Key Facts

- **Code size**: ~250 lines total, ~185 non-comment lines
- **Test coverage**: 100% required
- **Type safety**: No unnecessary `Any` (required for metaclass patterns)
- **Immutability**: All dataclasses frozen
- **Routing**: Explicit (NOT deterministic execution)
- **Single termination**: Exactly one route to `None` per flow

### Common Patterns

```python
from dataclasses import dataclass
from typing import override
from clearflow import Node, NodeResult, flow

# Creating nodes - Node is a frozen dataclass
@dataclass(frozen=True)
class DocumentLoader(Node[DocumentState]):
    name: str = "loader"
    
    @override
    async def exec(self, state: DocumentState) -> NodeResult[DocumentState]:
        content = await load_document(state["path"])
        new_state: DocumentState = {**state, "content": content}
        return NodeResult(new_state, outcome="loaded")

# Building a flow with single termination
loader = DocumentLoader()
processor = ProcessorNode()
complete = CompleteNode()

flow_instance = (
    flow("Pipeline", loader)
    .route(loader, "loaded", processor)
    .route(loader, "error", complete)
    .route(processor, "processed", complete)
    .end(complete, "done")  # Single termination
)
```

### Testing Requirements

- **100% coverage**: No exceptions, ever
- **Deep immutability**: Use frozen dataclasses or tuples for all test state
- **Real AI scenarios**: Model actual AI orchestration patterns (RAG, agents, tool use)
- **Functional purity**: Test that transformations are pure with no side effects
- **Precise types**: Every test knows exact TIn and TOut types
- **Educational tests**: Tests should demonstrate best practices for mission-critical AI

### Code Quality Standards

**CRITICAL**: These standards maintain trust:

- All linting rules must pass without suppression
- Pyright must pass in strict mode (sole type checker)
- Minimal `# pyright: ignore` comments (only for documented limitations)
- No `Any` types except where required (e.g., metaclass patterns)
- Prefer boring, obvious code over clever solutions

**LINTER SUPPRESSION POLICY**:

- **NEVER add linter suppressions without explicit user approval**
- This includes: `# noqa`, `# pyright: ignore`, etc.
- All approved suppressions MUST include a justification comment
- Example: `# noqa: C901  # Display function complexity acceptable for UI`
- Always fix the root cause instead of suppressing when possible

#### Custom Linters

ClearFlow uses three custom linters to enforce mission-critical standards:

1. **Architecture Compliance** (`linters/check-architecture-compliance.py`)
   - No patching/mocking of internal components in tests
   - No imports from private modules (`_internal`)
   - No use of `TYPE_CHECKING` (indicates circular dependencies)
   - No `object` or `Any` types in parameters

2. **Immutability Compliance** (`linters/check-immutability.py`)
   - All dataclasses must have `frozen=True`
   - No `list` in type annotations (use `tuple[T, ...]`)
   - No mutable default arguments
   - No list building with `.append()` in production code

3. **Test Suite Compliance** (`linters/check-test-suite-compliance.py`)
   - No `asyncio.run()` in tests (use `@pytest.mark.asyncio`)
   - No manual event loop creation without cleanup
   - All async tests must have `@pytest.mark.asyncio`
   - All resources must use context managers

These linters run automatically as part of `./quality-check.sh` and enforce zero-tolerance policies for violations.

### Contributing Guidelines

1. **PR Standards**
   - Must maintain 100% test coverage
   - Must pass all type checks
   - Must use frozen dataclasses
   - Must handle all outcomes explicitly

2. **Documentation**
   - Focus on guarantees and limitations
   - No marketing language
   - Examples must work exactly as shown
   - Be explicit about what we don't do

3. **Feature Requests**
   - Reject anything that compromises type safety
   - Reject anything that reduces testability
   - Reject anything that adds implicit behavior
   - "No" is a complete answer

### Documentation Style

**CRITICAL**: All documentation must be:

- **Factual and concise** - No verbosity or repetition
- **Free of "we/our" language** - Use neutral technical language
- **Focused on what matters** - Essential information only
- **Proportional** - Documentation should be shorter than the code (200 lines)
- **Ego-free** - No defensiveness, no overselling, no anxiety

Examples:

- ❌ "We provide trustworthy orchestration for mission-critical systems"
- ✅ "Reliable language model orchestration. Type-safe with 100% test coverage."
- ❌ "Our philosophy is trust through proof"
- ✅ "100% test coverage required"
- ❌ "This guide explains how to create high-quality examples"
- ✅ "Creating Examples"

**Documentation Smell Test**:
If documentation sounds anxious, defensive, or like it's trying to impress, rewrite it.
Good documentation states facts without emotion.

When responding to users:

- Be direct and factual
- State limitations without defensiveness
- Use technical language, not marketing speak
- Keep responses concise
- Don't explain why you can't do something (preachy)

### Red Flags to Avoid

1. **Never claim**:
   - "Deterministic orchestration" or "deterministic execution" (we only provide explicit routing)
   - "Exhaustive outcome handling" (we don't enforce this)
   - "Compile-time safety" (Python doesn't have this)
   - "Makes language model agents reliable" (we only provide orchestration structure)
   - "Production-ready agents" (we provide orchestration, not complete agents)
   - "You can't test LLM outputs" (you can test them, just not deterministically)

2. **Never add**:
   - Claims about execution order or timing guarantees
   - Methods that hide what happens between node calls
   - Optional parameters that change flow behavior
   - Dependencies that could introduce unpredictability

3. **Language to avoid**:
   - "Deterministic" when describing the framework (use "explicit routing" instead)
   - "Unreasonable AI" or other hyperbolic characterizations of LLMs
   - Absolute statements about what users can't do
   - Marketing language that can't be verified

### Before Any Change

Ask:

- Can this be tested completely?
- Does this make behavior more explicit?
- Is this simpler than the alternative?

If any answer is "no", don't do it.

### Git Workflow

1. **Branch Protection**: Main branch requires PR with passing checks
2. **Conventional Commits**: Use `fix:`, `feat:`, `docs:`, `ci:` prefixes
3. **Local Protection**: Pre-commit hook prevents direct commits to main
4. **PR Process**:

   ```bash
   git checkout -b type/description
   # Make changes
   ./quality-check.sh
   git commit -m "type: clear description"
   git push -u origin type/description
   gh pr create --title "type: description" --body "concise explanation"
   ```

## Remember

ClearFlow provides explicit routing with single termination enforcement. Keep the code minimal, the documentation concise, and the claims verifiable.

## Documentation Size Limits

ClearFlow is ~250 lines. Documentation should be proportional:

- README.md: Keep concise but complete (~200 lines is reasonable for user-facing docs)
- Individual docs: <100 lines
- Total documentation: <500 lines

Balance completeness with conciseness. The README needs to properly onboard users while staying focused.

## Release Process

ClearFlow uses automated release management:

1. **Version Management**: GitVersion calculates versions based on git history
2. **Draft Releases**: Release Drafter maintains draft with changelog from PR merges
3. **Publishing**: Manual trigger of release.yml workflow:
   - Builds package with calculated version
   - Creates git tag
   - Publishes to PyPI via trusted publisher
   - Converts draft to published GitHub release

**Known Issues**:

- Draft release IDs can become stale - always fetch fresh by tag name
- PyPI trusted publisher requires exact workflow path match
- Version must be updated in pyproject.toml before building

**PyPI Package**: <https://pypi.org/project/clearflow/>

## Critical Technical Distinctions

**Explicit routing ≠ Deterministic execution**

ClearFlow provides explicit routing (given outcome X, next step is always Y) but NOT deterministic execution (nodes execute arbitrary async code with unpredictable timing).

**Type Stub Best Practices**

- Stub only what you use (e.g., 6 DSPy APIs, not 127 files)
- Metaclass field descriptors must return `Any` (standard practice)
- Document why in stubs: `# Returns Any for metaclass transformation`
- Minimal stubs are maintainable; complete stubs are not

Always use precise technical terms. Users are engineers who will verify claims.

## Lessons Learned

1. **Documentation debt is real** - A 200-line library had 783 lines of docs (reduced to 150)
2. **Ego leaks into docs** - Watch for defensive language, "we/our", trying to sound important
3. **Less is more** - If you can say it in 20 lines instead of 100, do it
4. **Show, don't tell** - Code examples > philosophical manifestos
5. **Trust the code** - A well-written 200-line library doesn't need 450-line guides
6. **Be boring** - Boring, obvious code and docs are better than clever ones
7. **Mypy vs Pyright** - Pyright supports PEP 695 defaults, mypy doesn't. Use pyright only.
8. **Type stub maintenance** - Keep only what you use. 127 stubs for 6 APIs is waste.
9. **Metaclass patterns** - Must return `Any` from field constructors (industry standard)
10. **DSPy signatures** - They're Pydantic models with metaclass transformation</doc></documentation><examples><doc title="Chat" desc="Simple conversational flow with OpenAI integration"># Chat Example: Intelligent Entity Conversation

Demonstrates ClearFlow's power for modeling conversation as interaction between intelligent entities, a human and a language model, each with their own I/O capabilities and cognitive processes.

## Core Concept: Node == Intelligent Entity

Each node represents a **complete intelligent entity**:

- **HumanNode**: Human participant with console I/O and decision-making
- **LlmNode**: AI participant with API I/O and reasoning capabilities

This creates a natural conversation pattern between two intelligent entities.

## Flow

```mermaid
graph LR
    Start([Initial State]) --> human[HumanNode]
    human -->|responded| llm[LlmNode]
    human -->|quit| End([Terminate])
    llm -->|responded| human
```

## Quick Start

```bash
# From project root directory

# 1. Set up your OpenAI API key
cp .env.example .env
# Edit .env and add your API key

# 2. Install dependencies
uv sync --all-extras

# 3. Run the example
cd examples/chat
python main.py  # If venv is activated
# Or: uv run python main.py
```

## How It Works

This example models conversation as interaction between two intelligent entities:

### HumanNode - Complete Human Intelligence

- **Input**: Gets console input from user
- **Output**: Displays AI responses on console
- **Cognition**: Decides whether to continue or quit
- **Memory**: Manages human messages in conversation history

### LlmNode - Complete AI Intelligence  

- **Input**: Receives human messages from state
- **Output**: Generates responses via OpenAI API
- **Cognition**: Reasons about context and generates appropriate responses
- **Memory**: Manages AI responses in conversation history

The flow alternates between these two entities, creating a natural conversational pattern where each participant is a complete intelligent system with its own interface modalities.

## Key Features

- **Intelligent entities**: Each node represents a complete intelligent participant
- **Complete I/O**: Every entity handles its own input and output capabilities
- **Natural conversation**: Two entities alternating in dialogue
- **Clean abstraction**: Intelligence units rather than operational steps
- **Extensible pattern**: Easy to add more intelligent entities (databases, tools, etc.)

## Files

- `main.py` - Entry point that starts the intelligent entity conversation
- `nodes.py` - HumanNode and LlmNode intelligent entity implementations
- `chat_flow.py` - Two-node conversational flow definition</doc><doc title="Portfolio Analysis" desc="Simple conversational flow with OpenAI integration"># Portfolio Analysis Example

Multi-specialist workflow for portfolio allocation decisions using simulated market data.

## Flow

```mermaid
graph LR
    Start([Market Data]) --> Q[QuantAnalyst]
    Q -->|analysis_complete| R[RiskAnalyst]
    Q -->|analysis_failed| E[ErrorHandler]
    R -->|risk_acceptable| P[PortfolioManager]
    R -->|risk_limits_exceeded| E
    P -->|recommendations_ready| C[ComplianceOfficer]
    P -->|analysis_failed| E
    C -->|compliance_approved| D[DecisionNode]
    C -->|compliance_failed| E
    E -->|error_handled| D
    D -->|decision_ready| End([Final Decision])
```

## Quick Start

```bash
# From project root directory

# 1. Set up your OpenAI API key
cp .env.example .env
# Edit .env and add your API key

# 2. Install dependencies
uv sync --all-extras

# 3. Run the example
cd examples/portfolio_analysis
python main.py  # If venv is activated
# Or: uv run python main.py
```

## How It Works

This example demonstrates a sequential workflow where each specialist node analyzes market data and passes enriched state to the next stage:

1. **QuantAnalyst** - Technical analysis and opportunity identification
2. **RiskAnalyst** - Risk assessment and limit checking
3. **PortfolioManager** - Allocation recommendations
4. **ComplianceOfficer** - Regulatory validation
5. **DecisionNode** - Final synthesis and execution plan
6. **ErrorHandler** - Converts errors to conservative decisions

Each node uses DSPy for structured LLM outputs with Pydantic validation.

## Key Features

- **Sequential processing** - Each specialist processes in order
- **Type-safe transformations** - `MarketData → QuantInsights → RiskAssessment → Decision`
- **Error recovery** - Failures route to ErrorHandler then continue
- **Structured outputs** - DSPy signatures ensure consistent responses
- **Audit trail** - Complete reasoning chain for compliance

## Files

- `main.py` - Entry point with scenario selection
- `portfolio_flow.py` - Flow definition and routing
- `market_data.py` - Simulated market data generation
- `specialists/` - Individual specialist node implementations
- `shared/` - Common models and configuration</doc><doc title="RAG Pipeline" desc="Simple conversational flow with OpenAI integration"># RAG Example

Retrieval-Augmented Generation system demonstrating ClearFlow's type-safe state transformations.

## Flow

```mermaid
graph TD
    subgraph Offline Indexing Flow
        Start1([RAGState]) --> Chunk[ChunkDocumentsNode]
        Chunk -->|chunked| Embed[EmbedDocumentsNode]
        Embed -->|embedded| Index[CreateIndexNode]
        Index -->|indexed| End1([IndexedState])
    end
    
    subgraph Online Query Flow
        Start2([QueryState]) --> EmbedQ[EmbedQueryNode]
        EmbedQ -->|embedded| Retrieve[RetrieveDocumentNode]
        Retrieve -->|retrieved| Generate[GenerateAnswerNode]
        Generate -->|answered| End2([AnsweredState])
    end
```

## Quick Start

```bash
# From project root directory

# 1. Set up your OpenAI API key
cp .env.example .env
# Edit .env and add your API key

# 2. Install dependencies
uv sync --all-extras

# 3. Run the example
cd examples/rag
python main.py  # If venv is activated
# Or: uv run python main.py
# With custom query:
python main.py "What is Q-Mesh protocol?"
```

## How It Works

RAG combines document retrieval with language model generation. This implementation uses two flows:

**Offline Indexing Flow:**

- `ChunkDocuments` - Splits text into overlapping chunks (500 chars, 50 overlap)
- `EmbedDocuments` - Creates OpenAI embeddings for each chunk
- `CreateIndex` - Builds FAISS vector index for similarity search

**Online Query Flow:**

- `EmbedQuery` - Converts user query to embedding
- `RetrieveDocument` - Finds most similar chunk via cosine similarity
- `GenerateAnswer` - Uses GPT-4 with retrieved context to answer

Each transformation creates new immutable state: `RAGState → ChunkedState → EmbeddedState → IndexedState`

## Key Features

- **Two-phase architecture** - Separate indexing and query flows
- **Type-safe transformations** - Each node produces specific state types
- **Immutable state** - All transformations create new state objects
- **Vector search** - FAISS for efficient similarity matching
- **Explicit routing** - Clear flow definition with single termination

## Files

- `main.py` - Entry point and flow orchestration
- `nodes.py` - All node implementations
- `rag_flow.py` - Flow definitions and routing
- `models.py` - State type definitions
- `utils.py` - OpenAI and chunking utilities</doc></examples><testing><doc title="Error Handling" desc="Test error handling and edge cases for ClearFlow">"""Test error handling and edge cases for ClearFlow.

This module tests error conditions, edge cases, and validation logic
to ensure robust behavior in mission-critical scenarios.

"""

from dataclasses import dataclass, replace
from dataclasses import dataclass as dc
from typing import override

import pytest

from clearflow import Node, NodeResult, flow


@dataclass(frozen=True)
class SimpleState:
    """Simple typed state for testing."""

    test: str


@dataclass(frozen=True)
class ErrorState:
    """State for error handling tests."""

    simulate_error: bool
    error: str = ""
    response: str = ""
    handled: bool = False
    message: str = ""
    processed: bool = False


class TestErrorHandling:
    """Test error handling and edge cases."""

    @staticmethod
    async def test_missing_route() -> None:
        """Test that undefined routes raise an error."""

        @dc(frozen=True)
        class UnpredictableNode(Node[dict[str, str]]):
            """Node with variable outcomes."""

            name: str = "unpredictable"

            @override
            async def exec(self, state: dict[str, str]) -> NodeResult[dict[str, str]]:
                # Return an outcome that might not be routed
                outcome = state.get("force_outcome", "unexpected")
                return NodeResult(state, outcome=outcome)

        @dc(frozen=True)
        class TerminalNode(Node[dict[str, str]]):
            """Terminal node for expected outcome."""

            name: str = "terminal"

            @override
            async def exec(self, state: dict[str, str]) -> NodeResult[dict[str, str]]:
                return NodeResult(state, outcome="completed")

        unpredictable = UnpredictableNode()
        terminal = TerminalNode()

        # Flow with incomplete routing - unexpected outcome not routed
        incomplete_flow = (
            flow("IncompleteFlow", unpredictable).route(unpredictable, "expected", terminal).end(terminal, "completed")
            # "unexpected" outcome not routed - should raise error
        )

        # Should raise ValueError for unhandled outcome
        with pytest.raises(ValueError, match="No route defined for outcome 'unexpected' from node 'unpredictable'"):
            await incomplete_flow({"force_outcome": "unexpected"})

    @staticmethod
    async def test_empty_node_name() -> None:
        """Test that node names must be non-empty."""

        @dc(frozen=True)
        class BadNode(Node[SimpleState]):
            name: str = ""  # Empty name

            @override
            async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
                return NodeResult(state, outcome="done")

        with pytest.raises(ValueError, match="non-empty string"):
            BadNode()

        @dc(frozen=True)
        class WhitespaceNode(Node[SimpleState]):
            name: str = "   "  # Whitespace name

            @override
            async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
                return NodeResult(state, outcome="done")

        with pytest.raises(ValueError, match="non-empty string"):
            WhitespaceNode()

    @staticmethod
    async def test_node_with_valid_name() -> None:
        """Test that nodes must have explicit names."""

        @dc(frozen=True)
        class MyCustomNode(Node[SimpleState]):
            name: str = "custom_node"

            @override
            async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
                return NodeResult(state, outcome="done")

        # Node with explicit name
        node = MyCustomNode()
        assert node.name == "custom_node"

        # Override name in instantiation
        named_node = MyCustomNode(name="override_name")
        assert named_node.name == "override_name"

    @staticmethod
    async def test_single_node_flow() -> None:
        """Test a flow with a single node that terminates immediately."""

        @dataclass(frozen=True)
        class ProcessState:
            test: str
            processed: bool

        @dc(frozen=True)
        class StandaloneNode(Node[ProcessState]):
            name: str = "standalone"

            @override
            async def exec(self, state: ProcessState) -> NodeResult[ProcessState]:
                new_state = replace(state, processed=True)
                return NodeResult(new_state, outcome="complete")

        node = StandaloneNode()

        # Create flow with single node that terminates
        single_flow = flow("SingleNodeFlow", node).end(node, "complete")

        # Execute
        initial_state = ProcessState(test="value", processed=False)
        result = await single_flow(initial_state)
        assert result.outcome == "complete"
        assert result.state.test == "value"
        assert result.state.processed is True

    @staticmethod
    async def test_complex_error_flow() -> None:
        """Test error handling in AI workflows."""

        @dataclass(frozen=True)
        class LLMState:
            simulate_error: bool = False
            error: str = ""
            response: str = ""
            handled: bool = False
            message: str = ""
            processed: bool = False

        @dc(frozen=True)
        class LLMNode(Node[LLMState]):
            """Simulates LLM API that can fail."""

            name: str = "llm"

            @override
            async def exec(self, state: LLMState) -> NodeResult[LLMState]:
                if state.simulate_error:
                    error_state = replace(state, error="API timeout")
                    return NodeResult(error_state, outcome="error")
                success_state = replace(state, response="Generated text")
                return NodeResult(success_state, outcome="success")

        @dc(frozen=True)
        class ErrorHandler(Node[LLMState]):
            """Handles errors from LLM."""

            name: str = "error_handler"

            @override
            async def exec(self, state: LLMState) -> NodeResult[LLMState]:
                error = state.error or "Unknown error"
                new_state = replace(
                    state,
                    handled=True,
                    message=f"Error handled: {error}",
                )
                return NodeResult(new_state, outcome="handled")

        @dc(frozen=True)
        class SuccessHandler(Node[LLMState]):
            """Processes successful LLM responses."""

            name: str = "success_handler"

            @override
            async def exec(self, state: LLMState) -> NodeResult[LLMState]:
                new_state = replace(state, processed=True)
                return NodeResult(new_state, outcome="complete")

        llm = LLMNode()
        error_handler = ErrorHandler()
        success_handler = SuccessHandler()

        # Flow with error handling
        error_flow = (
            flow("ErrorHandlingFlow", llm)
            .route(llm, "error", error_handler)
            .route(llm, "success", success_handler)
            .end(error_handler, "handled")
            # Note: success_handler has a different termination, showcasing flexibility
        )

        # Test error path
        error_input = LLMState(simulate_error=True)
        error_result = await error_flow(error_input)
        assert error_result.outcome == "handled"
        assert error_result.state.handled is True
        assert "API timeout" in error_result.state.message</doc><doc title="Flow Tests" desc="Test Flow orchestration features of ClearFlow">"""Test Flow orchestration features of ClearFlow.

This module tests the Flow class functionality including linear flows,
branching, single termination enforcement, and flow composition.

"""

from dataclasses import dataclass, replace
from dataclasses import dataclass as dc
from typing import override

from clearflow import Node, NodeResult, flow
from tests.conftest import ValidationState


@dataclass(frozen=True)
class ChatState:
    """State for chat routing tests."""

    query: str = ""
    intent: str = ""
    agent: str = ""
    response_type: str = ""
    formatted: bool = False


@dataclass(frozen=True)
class DocState:
    """State for document processing tests."""

    source: str
    loaded: str = ""
    doc_count: str = ""
    embedded: str = ""
    embedding_dim: str = ""
    stored: str = ""


# Test nodes for chat routing - defined outside test to reduce complexity
@dc(frozen=True)
class IntentClassifier(Node[ChatState]):
    """Classifies user intent for appropriate AI response."""

    name: str = "classifier"

    @override
    async def exec(self, state: ChatState) -> NodeResult[ChatState]:
        query = state.query or ""
        intent = self._classify_intent(query)
        new_state = replace(state, intent=intent)
        return NodeResult(new_state, outcome=intent)

    def _classify_intent(self, query: str) -> str:
        """Classify query intent.

        Returns:
            Intent string: "technical", "question", or "general".
        """
        query_lower = str(query).lower()
        if "code" in query_lower or "bug" in query_lower:
            return "technical"
        if "?" in str(query):
            return "question"
        return "general"


@dc(frozen=True)
class TechnicalAgent(Node[ChatState]):
    """Handles technical queries with code examples."""

    name: str = "technical_agent"

    @override
    async def exec(self, state: ChatState) -> NodeResult[ChatState]:
        new_state = replace(
            state,
            agent="technical",
            response_type="code_example",
        )
        return NodeResult(new_state, outcome="responded")


@dc(frozen=True)
class QAAgent(Node[ChatState]):
    """Handles Q&A with retrieval augmented generation."""

    name: str = "qa_agent"

    @override
    async def exec(self, state: ChatState) -> NodeResult[ChatState]:
        new_state = replace(
            state,
            agent="qa",
            response_type="retrieved_answer",
        )
        return NodeResult(new_state, outcome="responded")


@dc(frozen=True)
class GeneralAgent(Node[ChatState]):
    """Handles general conversation."""

    name: str = "general_agent"

    @override
    async def exec(self, state: ChatState) -> NodeResult[ChatState]:
        new_state = replace(
            state,
            agent="general",
            response_type="chat",
        )
        return NodeResult(new_state, outcome="responded")


@dc(frozen=True)
class ResponseFormatter(Node[ChatState]):
    """Formats final response for user."""

    name: str = "formatter"

    @override
    async def exec(self, state: ChatState) -> NodeResult[ChatState]:
        new_state = replace(state, formatted=True)
        return NodeResult(new_state, outcome="complete")


# Test data classes and nodes for linear flow
@dc(frozen=True)
class RawText:
    """Raw text to be processed."""

    content: str
    source: str


@dc(frozen=True)
class TokenizedText:
    """Text split into tokens."""

    raw: RawText
    tokens: tuple[str, ...]


@dc(frozen=True)
class IndexedDocument:
    """Final indexed document."""

    tokenized: TokenizedText
    token_count: int
    indexed: bool = True


@dc(frozen=True)
class TokenizerNode(Node[RawText, TokenizedText]):
    """Tokenizes text for embedding generation."""

    name: str = "tokenizer"

    @override
    async def exec(self, state: RawText) -> NodeResult[TokenizedText]:
        tokens = tuple(state.content.split())
        tokenized = TokenizedText(raw=state, tokens=tokens)
        return NodeResult(tokenized, outcome="tokenized")


@dc(frozen=True)
class IndexerNode(Node[TokenizedText, IndexedDocument]):
    """Creates embeddings and indexes document."""

    name: str = "indexer"

    @override
    async def exec(self, state: TokenizedText) -> NodeResult[IndexedDocument]:
        indexed = IndexedDocument(tokenized=state, token_count=len(state.tokens))
        return NodeResult(indexed, outcome="indexed")


# Nodes for nested flow testing
@dc(frozen=True)
class DocumentLoader(Node[DocState]):
    """Loads documents for processing."""

    name: str = "loader"

    @override
    async def exec(self, state: DocState) -> NodeResult[DocState]:
        new_state = replace(state, loaded="true", doc_count="5")
        return NodeResult(new_state, outcome="loaded")


@dc(frozen=True)
class Embedder(Node[DocState]):
    """Creates embeddings from loaded documents."""

    name: str = "embedder"

    @override
    async def exec(self, state: DocState) -> NodeResult[DocState]:
        new_state = replace(
            state,
            embedded="true",
            embedding_dim="768",
        )
        return NodeResult(new_state, outcome="embedded")


@dc(frozen=True)
class VectorStore(Node[DocState]):
    """Stores embeddings in vector database."""

    name: str = "vector_store"

    @override
    async def exec(self, state: DocState) -> NodeResult[DocState]:
        new_state = replace(state, stored="true")
        return NodeResult(new_state, outcome="indexed")


class TestFlow:
    """Test the Flow orchestration."""

    @staticmethod
    async def test_linear_flow_build() -> None:
        """Test building a linear flow."""
        tokenizer = TokenizerNode()
        indexer = IndexerNode()

        flow_instance = flow("RAG", tokenizer).route(tokenizer, "tokenized", indexer).end(indexer, "indexed")

        assert flow_instance.name == "RAG"

    @staticmethod
    async def test_linear_flow_execution() -> None:
        """Test executing a linear flow."""
        tokenizer = TokenizerNode()
        indexer = IndexerNode()

        flow_instance = flow("RAG", tokenizer).route(tokenizer, "tokenized", indexer).end(indexer, "indexed")

        initial = RawText(content="Natural language processing", source="test.txt")
        result = await flow_instance(initial)

        assert result.outcome == "indexed"
        assert isinstance(result.state, IndexedDocument)
        assert result.state.token_count == 3

    @staticmethod
    async def test_chat_routing_flow_setup() -> None:
        """Test building an AI chat routing flow."""
        # Build AI chat routing flow using new API
        classifier = IntentClassifier()
        technical = TechnicalAgent()
        qa = QAAgent()
        general = GeneralAgent()
        formatter = ResponseFormatter()

        chat_flow = (
            flow("ChatRouter", classifier)
            .route(classifier, "technical", technical)
            .route(classifier, "question", qa)
            .route(classifier, "general", general)
            .route(technical, "responded", formatter)
            .route(qa, "responded", formatter)
            .route(general, "responded", formatter)
            .end(formatter, "complete")
        )

        # Just verify flow builds correctly
        assert chat_flow.name == "ChatRouter"

    @staticmethod
    async def test_chat_technical_path() -> None:
        """Test technical query routing in chat flow."""
        classifier = IntentClassifier()
        technical = TechnicalAgent()
        formatter = ResponseFormatter()

        chat_flow = (
            flow("TechRouter", classifier)
            .route(classifier, "technical", technical)
            .route(technical, "responded", formatter)
            .end(formatter, "complete")
        )

        tech_input = ChatState(query="How do I fix this bug in my code?")
        result = await chat_flow(tech_input)
        assert result.state.intent == "technical"
        assert result.state.agent == "technical"
        assert result.outcome == "complete"

    @staticmethod
    async def test_chat_question_path() -> None:
        """Test question routing in chat flow."""
        classifier = IntentClassifier()
        qa = QAAgent()
        formatter = ResponseFormatter()

        chat_flow = (
            flow("QARouter", classifier)
            .route(classifier, "question", qa)
            .route(qa, "responded", formatter)
            .end(formatter, "complete")
        )

        question_input = ChatState(query="What is RAG?")
        result = await chat_flow(question_input)
        assert result.state.intent == "question"
        assert result.state.agent == "qa"
        assert result.outcome == "complete"

    @staticmethod
    async def test_chat_general_path() -> None:
        """Test general conversation routing."""
        classifier = IntentClassifier()
        general = GeneralAgent()
        formatter = ResponseFormatter()

        chat_flow = (
            flow("GeneralRouter", classifier)
            .route(classifier, "general", general)
            .route(general, "responded", formatter)
            .end(formatter, "complete")
        )

        input_state = ChatState(query="Hello there")
        result = await chat_flow(input_state)
        assert result.state.intent == "general"
        assert result.state.agent == "general"
        assert result.outcome == "complete"

    @staticmethod
    async def test_single_termination_enforcement() -> None:
        """Test that flows must have exactly one termination point."""

        @dc(frozen=True)
        class DataValidator(Node[ValidationState]):
            """Validates incoming data for processing."""

            name: str = "validator"

            @override
            async def exec(self, state: ValidationState) -> NodeResult[ValidationState]:
                return NodeResult(state, outcome="valid")

        @dc(frozen=True)
        class DataProcessor(Node[ValidationState]):
            """Processes validated data."""

            name: str = "processor"

            @override
            async def exec(self, state: ValidationState) -> NodeResult[ValidationState]:
                return NodeResult(state, outcome="processed")

        validator = DataValidator()
        processor = DataProcessor()

        # This works - single termination point
        valid_flow = (
            flow("ValidationPipeline", validator).route(validator, "valid", processor).end(processor, "processed")
        )

        # Test that it runs successfully
        result = await valid_flow(ValidationState(input_text="test data"))
        assert result.outcome == "processed"

    @staticmethod
    async def test_flow_composition() -> None:
        """Test that flows can be composed as nodes."""
        loader = DocumentLoader()
        embedder = Embedder()

        # Create inner flow
        inner_flow = flow("Inner", loader).route(loader, "loaded", embedder).end(embedder, "embedded")

        # Use inner flow as a node
        vector_store = VectorStore()
        outer_flow = flow("Outer", inner_flow).route(inner_flow, "embedded", vector_store).end(vector_store, "indexed")

        # Just verify it builds
        assert outer_flow.name == "Outer"

    @staticmethod
    async def test_nested_flow_execution() -> None:
        """Test execution of nested flows."""
        loader = DocumentLoader()
        embedder = Embedder()
        doc_flow = flow("DocFlow", loader).route(loader, "loaded", embedder).end(embedder, "embedded")

        vector_store = VectorStore()
        pipeline = flow("Pipeline", doc_flow).route(doc_flow, "embedded", vector_store).end(vector_store, "indexed")

        doc_input = DocState(
            source="kb",
            loaded="",
            doc_count="",
            embedded="",
            embedding_dim="",
            stored="",
        )
        result = await pipeline(doc_input)
        assert result.outcome == "indexed"
        assert result.state.stored == "true"</doc><doc title="Flow Validation" desc="Test flow builder validation for reachability and duplicate routes">"""Test flow builder validation for reachability and duplicate routes.

This module tests that the flow builder enforces:
1. Nodes can only be routed from if reachable from start
2. Routes cannot be duplicated
3. Termination nodes must be reachable

"""

from dataclasses import dataclass
from typing import override

import pytest

from clearflow import Node, NodeResult, flow


@dataclass(frozen=True)
class SimpleState:
    """Simple state for testing."""

    value: str


@dataclass(frozen=True)
class SimpleNode(Node[SimpleState]):
    """Basic node for testing."""

    name: str

    @override
    async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
        return NodeResult(state, outcome="done")


class TestReachabilityValidation:
    """Test that nodes must be reachable to be used."""

    @staticmethod
    async def test_valid_linear_flow() -> None:
        """Test that a properly connected linear flow works."""
        start = SimpleNode(name="start")
        middle = SimpleNode(name="middle")
        end = SimpleNode(name="end")

        # This should work - all nodes are reachable
        valid_flow = flow("ValidFlow", start).route(start, "done", middle).route(middle, "done", end).end(end, "done")

        result = await valid_flow(SimpleState("test"))
        assert result.state.value == "test"

    @staticmethod
    async def test_valid_branching_flow() -> None:
        """Test that branching flows work when all nodes are reachable."""
        branch_a = SimpleNode(name="branch_a")
        branch_b = SimpleNode(name="branch_b")
        final = SimpleNode(name="final")

        @dataclass(frozen=True)
        class BranchingNode(Node[SimpleState]):
            name: str = "start"

            @override
            async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
                if state.value == "a":
                    return NodeResult(state, outcome="path_a")
                return NodeResult(state, outcome="path_b")

        start_branching = BranchingNode()

        # All branches properly connected
        branching_flow = (
            flow("BranchingFlow", start_branching)
            .route(start_branching, "path_a", branch_a)
            .route(start_branching, "path_b", branch_b)
            .route(branch_a, "done", final)
            .route(branch_b, "done", final)
            .end(final, "done")
        )

        result = await branching_flow(SimpleState("a"))
        assert result.state.value == "a"

    @staticmethod
    def test_routing_from_unreachable_node() -> None:
        """Test that routing from an unreachable node raises an error."""
        start = SimpleNode(name="start")
        orphan = SimpleNode(name="orphan")
        end = SimpleNode(name="end")

        # This should fail - orphan is never routed to
        with pytest.raises(ValueError, match="Cannot route from 'orphan' - not reachable"):
            flow("InvalidFlow", start).route(orphan, "done", end).end(end, "done")

    @staticmethod
    def test_ending_at_unreachable_node() -> None:
        """Test that ending at an unreachable node raises an error."""
        start = SimpleNode(name="start")
        middle = SimpleNode(name="middle")
        unreachable_end = SimpleNode(name="unreachable_end")

        # This should fail - unreachable_end is never routed to
        with pytest.raises(ValueError, match="Cannot end at 'unreachable_end' - not reachable"):
            flow("InvalidFlow", start).route(start, "done", middle).end(unreachable_end, "done")

    @staticmethod
    def test_disconnected_subgraph() -> None:
        """Test that disconnected subgraphs are detected."""
        start = SimpleNode(name="start")
        middle = SimpleNode(name="middle")

        # Create disconnected nodes
        island1 = SimpleNode(name="island1")
        island2 = SimpleNode(name="island2")

        # This should fail - island1 is not reachable from start
        with pytest.raises(ValueError, match="Cannot route from 'island1' - not reachable"):
            (
                flow("DisconnectedFlow", start)
                .route(start, "done", middle)
                .route(island1, "done", island2)  # Disconnected subgraph!
                .end(middle, "done")
            )

    @staticmethod
    def test_complex_reachability() -> None:
        """Test reachability with more complex routing patterns."""
        start = SimpleNode(name="start")
        a = SimpleNode(name="a")
        b = SimpleNode(name="b")
        c = SimpleNode(name="c")
        d = SimpleNode(name="d")

        # Build a flow where d is only reachable through a specific path
        complex_flow = (
            flow("ComplexFlow", start)
            .route(start, "to_a", a)
            .route(start, "to_b", b)
            .route(a, "to_c", c)
            .route(c, "to_d", d)
            # b can also go to d - this should work since d is reachable via a->c->d
            .route(b, "to_d", d)
            .end(d, "done")
        )

        # This should work - all nodes are properly connected
        assert complex_flow is not None


class TestDuplicateRouteDetection:
    """Test that duplicate routes are detected and prevented."""

    @staticmethod
    def test_duplicate_route_same_outcome() -> None:
        """Test that defining the same route twice raises an error."""
        start = SimpleNode(name="start")
        option1 = SimpleNode(name="option1")
        option2 = SimpleNode(name="option2")

        # This should fail - can't route "done" from start twice
        with pytest.raises(ValueError, match="Route already defined for outcome 'done' from node 'start'"):
            (
                flow("DuplicateRoute", start).route(start, "done", option1).route(start, "done", option2)  # Duplicate!
            )

    @staticmethod
    def test_same_outcome_different_nodes_allowed() -> None:
        """Test that same outcome from different nodes is allowed."""
        start = SimpleNode(name="start")
        middle1 = SimpleNode(name="middle1")
        middle2 = SimpleNode(name="middle2")
        end = SimpleNode(name="end")

        # This should work - same outcome but from different nodes
        valid_flow = (
            flow("ValidSameOutcome", start)
            .route(start, "path1", middle1)
            .route(start, "path2", middle2)
            .route(middle1, "done", end)  # "done" from middle1
            .route(middle2, "done", end)  # "done" from middle2 - OK!
            .end(end, "done")
        )

        assert valid_flow is not None

    @staticmethod
    def test_duplicate_termination_route() -> None:
        """Test that trying to add a route that conflicts with termination fails."""
        start = SimpleNode(name="start")
        middle = SimpleNode(name="middle")
        end = SimpleNode(name="end")

        # Try to route and terminate with the same outcome from same node
        with pytest.raises(ValueError, match="Route already defined for outcome 'done' from node 'end'"):
            (
                flow("DuplicateTermination", start)
                .route(start, "done", end)
                .route(end, "done", middle)  # First route from end
                .end(end, "done")  # Can't terminate with same outcome!
            )

    @staticmethod
    def test_route_then_terminate_same_outcome() -> None:
        """Test that routing and terminating with same outcome fails."""
        start = SimpleNode(name="start")
        middle = SimpleNode(name="middle")

        # This should fail - can't have both route and termination for same outcome
        with pytest.raises(ValueError, match="Route already defined for outcome 'done' from node 'middle'"):
            (
                flow("RouteAndTerminate", start)
                .route(start, "done", middle)
                .route(middle, "done", start)  # Creates a loop
                .end(middle, "done")  # Same outcome as the route above!
            )

    @staticmethod
    async def test_multiple_outcomes_single_node() -> None:
        """Test that a node can have multiple different outcomes."""

        @dataclass(frozen=True)
        class MultiOutcomeNode(Node[SimpleState]):
            name: str = "multi"

            @override
            async def exec(self, state: SimpleState) -> NodeResult[SimpleState]:
                if state.value == "error":
                    return NodeResult(state, outcome="error")
                if state.value == "retry":
                    return NodeResult(state, outcome="retry")
                return NodeResult(state, outcome="success")

        multi = MultiOutcomeNode()
        error_handler = SimpleNode(name="error_handler")
        retry_handler = SimpleNode(name="retry_handler")
        success_handler = SimpleNode(name="success_handler")

        # This should work - different outcomes from same node
        multi_flow = (
            flow("MultiOutcome", multi)
            .route(multi, "error", error_handler)
            .route(multi, "retry", retry_handler)
            .route(multi, "success", success_handler)
            .end(error_handler, "done")
            # Note: other handlers not terminated for this test
        )

        result = await multi_flow(SimpleState("error"))
        assert result.state.value == "error"</doc><doc title="Node Tests" desc="Test Node abstraction features of ClearFlow">"""Test Node abstraction features of ClearFlow.

This module tests the Node class functionality including lifecycle hooks,
lifecycle hooks, and routing patterns for mission-critical AI orchestration.

"""

from dataclasses import dataclass as dc
from dataclasses import replace
from typing import override

from clearflow import Node, NodeResult
from tests.conftest import AgentState, Message, ValidationState

# Module-level test nodes to reduce complexity


@dc(frozen=True)
class TokenCountNode(Node[ValidationState]):
    """Node for token counting in LLM validation."""

    name: str = "token_counter"

    @override
    async def exec(self, state: ValidationState) -> NodeResult[ValidationState]:
        # Transformation: count tokens (simplified)
        token_count = len(state.input_text.split())

        if token_count > 100:
            errors = (*state.errors, f"Token count {token_count} exceeds limit")
            new_state = replace(state, errors=errors, validated=False)
            outcome = "too_long"
        else:
            new_state = replace(state, validated=True)
            outcome = "valid_length"

        return NodeResult(new_state, outcome=outcome)


@dc(frozen=True)
class PromptState:
    """Immutable state for prompt engineering pipeline."""

    raw_prompt: str
    sanitized: bool = False
    validated: bool = False
    enhanced: bool = False


@dc(frozen=True)
class PromptEngineeringNode(Node[PromptState]):
    """Node demonstrating lifecycle hooks for prompt engineering."""

    name: str = "prompt_engineer"

    @override
    async def prep(self, state: PromptState) -> PromptState:
        # Sanitize prompt in prep phase
        return replace(state, sanitized=True)

    @override
    async def exec(self, state: PromptState) -> NodeResult[PromptState]:
        # Validate prompt in main execution
        new_state = replace(state, validated=True)
        return NodeResult(new_state, outcome="validated")

    @override
    async def post(
        self,
        result: NodeResult[PromptState],
    ) -> NodeResult[PromptState]:
        # Enhance prompt in post phase
        new_state = replace(result.state, enhanced=True)
        return NodeResult(new_state, outcome=result.outcome)


@dc(frozen=True)
class LLMRouterNode(Node[AgentState]):
    """Routes to different paths based on LLM analysis."""

    name: str = "llm_router"

    @override
    async def exec(self, state: AgentState) -> NodeResult[AgentState]:
        # Analyze last user message for intent (simulating LLM classification)
        last_msg = state.messages[-1] if state.messages else None

        # Determine outcome and response based on message content
        outcome, response = self._classify_intent(last_msg)

        # Immutable state update
        new_state = AgentState(
            messages=(*state.messages, response),
            context=state.context,
            temperature=0.3 if outcome == "code_generation" else state.temperature,
        )
        return NodeResult(new_state, outcome=outcome)

    def _classify_intent(self, msg: Message | None) -> tuple[str, Message]:
        """Classify user intent from message.

        Returns:
            Tuple of (intent string, response message).
        """
        if not msg or msg.role != "user":
            return "no_input", Message(role="assistant", content="Please provide input.")

        content_lower = msg.content.lower()
        if "weather" in content_lower:
            return "tool_required", Message(
                role="assistant",
                content="I'll check the weather for you.",
            )
        if "code" in content_lower:
            return "code_generation", Message(
                role="assistant",
                content="I'll help you write code.",
            )

        return "direct_response", Message(
            role="assistant",
            content="I understand your request.",
        )


class TestNode:
    """Test the Node abstraction."""

    @staticmethod
    async def test_immutable_transformations() -> None:
        """Test that nodes perform immutable transformations - same input produces same output."""
        node = TokenCountNode()
        initial = ValidationState(input_text="Short prompt for testing")

        # Multiple calls with same input produce same output (immutable transformations)
        result1 = await node(initial)
        result2 = await node(initial)

        assert result1.state == result2.state
        assert result1.outcome == result2.outcome

    @staticmethod
    async def test_validation_success() -> None:
        """Test successful validation for short text."""
        node = TokenCountNode()
        initial = ValidationState(input_text="Short prompt for testing")

        result = await node(initial)

        assert result.state.validated is True
        assert result.outcome == "valid_length"
        # Verify immutability
        assert initial.validated is False

    @staticmethod
    async def test_validation_failure() -> None:
        """Test validation failure for long text."""
        node = TokenCountNode()
        # Create text with more than 100 words
        long_text = " ".join(["word"] * 101)
        initial = ValidationState(input_text=long_text)

        result = await node(initial)

        assert result.state.validated is False
        assert result.outcome == "too_long"
        assert len(result.state.errors) == 1
        assert "exceeds limit" in result.state.errors[0]

    @staticmethod
    async def test_lifecycle_hooks() -> None:
        """Test that prep and post hooks work correctly."""
        node = PromptEngineeringNode()
        initial = PromptState(raw_prompt="Explain quantum computing")
        result = await node(initial)

        assert result.state.sanitized is True
        assert result.state.validated is True
        assert result.state.enhanced is True
        assert initial.sanitized is False  # Original unchanged

    @staticmethod
    async def test_router_no_input() -> None:
        """Test router handles missing user input."""
        node = LLMRouterNode()
        empty_state = AgentState(messages=(), context="assistant")
        result = await node(empty_state)

        assert result.outcome == "no_input"
        assert "Please provide input" in result.state.messages[0].content

    @staticmethod
    async def test_router_tool_required() -> None:
        """Test router identifies tool-required intent."""
        node = LLMRouterNode()
        weather_state = AgentState(
            messages=(Message(role="user", content="What's the weather in NYC?"),),
            context="weather_assistant",
        )
        result = await node(weather_state)

        assert result.outcome == "tool_required"
        assert len(result.state.messages) == 2
        assert "check the weather" in result.state.messages[-1].content

    @staticmethod
    async def test_router_code_generation() -> None:
        """Test router identifies code generation intent and adjusts temperature."""
        node = LLMRouterNode()
        code_state = AgentState(
            messages=(Message(role="user", content="Help me write Python code"),),
            context="coding_assistant",
            temperature=0.7,
        )
        result = await node(code_state)

        assert result.outcome == "code_generation"
        assert result.state.temperature == 0.3  # Lowered for code generation
        assert "write code" in result.state.messages[-1].content

    @staticmethod
    async def test_router_direct_response() -> None:
        """Test router handles general queries."""
        node = LLMRouterNode()
        general_state = AgentState(
            messages=(Message(role="user", content="Tell me about history"),),
            context="assistant",
        )
        result = await node(general_state)

        assert result.outcome == "direct_response"
        assert "understand your request" in result.state.messages[-1].content</doc><doc title="Type Transformations" desc="Test type transformation features of ClearFlow">"""Test type transformation features of ClearFlow.

This module tests Node[TIn, TOut] type transformations for real AI pipelines,
demonstrating how to avoid "god objects" through type-safe transformations.

"""

from dataclasses import dataclass as dc
from typing import override

from clearflow import Node, NodeResult
from tests.conftest import Document


# RAG pipeline types
@dc(frozen=True)
class Query:
    """User query for RAG system."""

    text: str
    max_results: int = 5


@dc(frozen=True)
class SearchResults:
    """Retrieved documents with scores."""

    query: Query
    documents: tuple[tuple[Document, float], ...]  # (doc, relevance_score)


@dc(frozen=True)
class Context:
    """Prepared context for generation."""

    query: Query
    relevant_texts: tuple[str, ...]
    total_tokens: int


@dc(frozen=True)
class Response:
    """Final generated response."""

    query: Query
    answer: str
    sources: tuple[str, ...]


@dc(frozen=True)
class RetrievalNode(Node[Query, SearchResults]):
    """Retrieves relevant documents."""

    name: str = "retriever"

    @override
    async def exec(self, state: Query) -> NodeResult[SearchResults]:
        # Simulate retrieval
        mock_docs = (
            (Document("AI is transforming industries", "doc1.pdf"), 0.95),
            (Document("Machine learning applications", "doc2.pdf"), 0.87),
        )
        results = SearchResults(query=state, documents=mock_docs[: state.max_results])
        return NodeResult(results, outcome="retrieved")


@dc(frozen=True)
class ContextBuilder(Node[SearchResults, Context]):
    """Builds context from search results."""

    name: str = "context_builder"

    @override
    async def exec(self, state: SearchResults) -> NodeResult[Context]:
        texts = tuple(doc.content for doc, _ in state.documents)
        tokens = sum(len(text.split()) for text in texts)
        context = Context(query=state.query, relevant_texts=texts, total_tokens=tokens)
        outcome = "context_ready" if tokens < 1000 else "context_too_long"
        return NodeResult(context, outcome=outcome)


@dc(frozen=True)
class GenerationNode(Node[Context, Response]):
    """Generates response from context."""

    name: str = "generator"

    @override
    async def exec(self, state: Context) -> NodeResult[Response]:
        # Simulate generation
        answer = f"Based on {len(state.relevant_texts)} sources: " + state.relevant_texts[0][:50]
        sources = tuple(f"doc{i + 1}.pdf" for i in range(len(state.relevant_texts)))
        response = Response(query=state.query, answer=answer, sources=sources)
        return NodeResult(response, outcome="generated")


class TestTypeTransformations:
    """Test Node[TIn, TOut] type transformations for real AI pipelines."""

    @staticmethod
    async def test_rag_retrieval_transformation() -> None:
        """Test Query to SearchResults transformation."""
        query = Query(text="How is AI transforming industries?", max_results=2)
        retrieval = RetrievalNode()
        result = await retrieval(query)
        assert isinstance(result.state, SearchResults)
        assert len(result.state.documents) == 2

    @staticmethod
    async def test_rag_context_building() -> None:
        """Test SearchResults to Context transformation."""
        query = Query(text="AI query", max_results=2)
        mock_results = SearchResults(
            query=query,
            documents=(
                (Document("AI content", "doc1.pdf"), 0.95),
                (Document("ML content", "doc2.pdf"), 0.87),
            ),
        )
        builder = ContextBuilder()
        result = await builder(mock_results)
        assert isinstance(result.state, Context)
        assert result.state.total_tokens > 0

    @staticmethod
    async def test_rag_generation() -> None:
        """Test Context to Response transformation."""
        query = Query(text="test", max_results=1)
        context = Context(query=query, relevant_texts=("Test content",), total_tokens=2)
        generator = GenerationNode()
        result = await generator(context)
        assert isinstance(result.state, Response)
        assert result.state.query == query
        assert len(result.state.sources) > 0

    @staticmethod
    async def test_tool_planning() -> None:
        """Test tool planning transformation."""

        # Tool types
        @dc(frozen=True)
        class ToolQuery:
            question: str
            context: str = ""

        @dc(frozen=True)
        class ToolPlan:
            query: ToolQuery
            selected_tool: str
            parameters: tuple[tuple[str, str], ...]

        @dc(frozen=True)
        class SimplePlanner(Node[ToolQuery, ToolPlan]):
            name: str = "planner"

            @override
            async def exec(self, state: ToolQuery) -> NodeResult[ToolPlan]:
                tool = "calculator" if "calculate" in state.question.lower() else "none"
                params = (("expr", state.question),) if tool != "none" else ()
                plan = ToolPlan(query=state, selected_tool=tool, parameters=params)
                return NodeResult(plan, outcome="planned")

        query = ToolQuery(question="Calculate 6 * 7")
        planner = SimplePlanner()
        result = await planner(query)
        assert isinstance(result.state, ToolPlan)
        assert result.state.selected_tool == "calculator"

    @staticmethod
    async def test_tool_execution() -> None:
        """Test tool execution transformation."""

        @dc(frozen=True)
        class ToolQuery:
            question: str

        @dc(frozen=True)
        class ToolPlan:
            query: ToolQuery
            selected_tool: str

        @dc(frozen=True)
        class ToolResult:
            plan: ToolPlan
            output: str
            success: bool

        @dc(frozen=True)
        class SimpleExecutor(Node[ToolPlan, ToolResult]):
            name: str = "executor"

            @override
            async def exec(self, state: ToolPlan) -> NodeResult[ToolResult]:
                output = "Result: 42" if state.selected_tool == "calculator" else "None"
                success = state.selected_tool == "calculator"
                result = ToolResult(plan=state, output=output, success=success)
                return NodeResult(result, outcome="executed")

        query = ToolQuery(question="test")
        plan = ToolPlan(query=query, selected_tool="calculator")
        executor = SimpleExecutor()
        result = await executor(plan)
        assert isinstance(result.state, ToolResult)
        assert result.state.success is True</doc></testing><optional><doc title="Migration Guide" desc="This guide covers breaking changes and migration steps for ClearFlow v1.0."># Migration Guide: v0.x to v1.0

This guide covers breaking changes and migration steps for ClearFlow v1.0.

## Breaking Changes

### 1. Node Type Parameters

**Before:** Single type parameter

```python
class MyNode(Node[StateType]):
    async def exec(self, state: StateType) -> NodeResult[StateType]:
        ...
```

**After:** Input/Output type parameters

```python
@dataclass(frozen=True)
class MyNode(Node[StateType]):  # TOut defaults to TIn
    name: str = "my_node"
    
    @override
    async def exec(self, state: StateType) -> NodeResult[StateType]:
        ...

# Or with transformation:
@dataclass(frozen=True)
class TransformNode(Node[InputType, OutputType]):
    name: str = "transformer"
    
    @override
    async def exec(self, state: InputType) -> NodeResult[OutputType]:
        ...
```

### 2. Node Name Required

**Before:** Name defaults to class name

```python
class MyNode(Node[T]):
    # name automatically becomes "MyNode"
    pass
```

**After:** Name must be explicit

```python
@dataclass(frozen=True)
class MyNode(Node[T]):
    name: str = "my_node"  # Required field
```

### 3. Flow API Replaced

**Before:** Flow class with add() method

```python
flow = Flow(name="pipeline", start_node=start)
flow.add(start, "success", processor)
flow.add(processor, "done", None)  # Termination
```

**After:** flow() function with builder pattern

```python
flow_instance = (
    flow("pipeline", start)
    .route(start, "success", processor)
    .end(processor, "done")  # Single termination via end()
)
```

### 4. Single Termination Enforcement

**Before:** Multiple terminations allowed

```python
flow.add(node1, "outcome1", None)
flow.add(node2, "outcome2", None)  # Multiple terminations OK
```

**After:** Exactly one termination via end()

```python
flow_instance = (
    flow("pipeline", start)
    .route(start, "path1", node1)
    .route(start, "path2", node2)
    .route(node1, "done", node2)
    .end(node2, "complete")  # Only one end() allowed
)
```

### 5. Reachability Validation

**New:** Cannot route from unreachable nodes

```python
# This will raise ValueError:
flow_instance = (
    flow("pipeline", start)
    .route(unreachable_node, "outcome", end)  # Error: unreachable_node not reachable
    .end(end, "done")
)
```

### 6. Frozen Dataclasses Required

**Before:** Regular classes

```python
class MyNode(Node[T]):
    def __init__(self):
        self.mutable_field = []  # Mutable state allowed
```

**After:** Frozen dataclasses only

```python
@dataclass(frozen=True)
class MyNode(Node[T]):
    name: str = "my_node"
    # All fields must be immutable
```

## Migration Steps

### Step 1: Update Node Definitions

1. Add `@dataclass(frozen=True)` decorator
2. Add explicit `name` field
3. Add `@override` decorator to `exec()`
4. Update type parameters if transforming state

### Step 2: Replace Flow Usage

1. Replace `Flow()` with `flow()` function
2. Replace `.add()` calls with `.route()`
3. Replace termination `add(node, outcome, None)` with `.end(node, outcome)`
4. Ensure only one `.end()` call per flow

### Step 3: Update State Types

1. Ensure all state types are immutable (frozen dataclasses or tuples)
2. Replace mutable operations with `dataclasses.replace()`
3. Use tuples instead of lists for collections

### Step 4: Fix Import Statements

**Before:**

```python
from clearflow import Flow, Node, NodeResult
```

**After:**

```python
from clearflow import flow, Node, NodeResult  # flow is lowercase function
```

## Complete Example

**Before:**

```python
from clearflow import Flow, Node, NodeResult

class ProcessNode(Node[dict]):
    async def exec(self, state: dict) -> NodeResult[dict]:
        state["processed"] = True
        return NodeResult(state, outcome="done")

process = ProcessNode()
flow = Flow(name="pipeline", start_node=process)
flow.add(process, "done", None)
```

**After:**

```python
from dataclasses import dataclass
from typing import override
from clearflow import flow, Node, NodeResult

@dataclass(frozen=True)
class State:
    data: str
    processed: bool = False

@dataclass(frozen=True)
class ProcessNode(Node[State]):
    name: str = "processor"
    
    @override
    async def exec(self, state: State) -> NodeResult[State]:
        from dataclasses import replace
        new_state = replace(state, processed=True)
        return NodeResult(new_state, outcome="done")

process = ProcessNode()
pipeline = flow("pipeline", process).end(process, "done")
```

## Common Issues

### TypeError: Missing required 'name' field

**Solution:** Add `name: str = "node_name"` to your node class

### ValueError: No route defined for outcome

**Solution:** Ensure all possible outcomes have routes or terminations

### ValueError: Cannot route from 'node' - not reachable

**Solution:** Ensure nodes are connected in order from start node

### AttributeError: 'Flow' object has no attribute 'add'

**Solution:** Replace Flow class with flow() function and builder pattern

## Need Help?

See the [examples](examples/) directory for complete working code with the new API.</doc><doc title="License" desc="MIT License">MIT License

Copyright (c) 2025 ClearFlow Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</doc></optional></project>
